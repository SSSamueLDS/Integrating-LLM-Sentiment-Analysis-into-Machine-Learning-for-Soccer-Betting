{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9cfcad4",
   "metadata": {},
   "source": [
    "<h1>Sentiment Analysis with LLMs</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964eb0b8",
   "metadata": {},
   "source": [
    "Deepseek API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b85899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called API 5 times\n",
      "Called API 10 times\n",
      "Called API 15 times\n",
      "Called API 20 times\n",
      "Called API 25 times\n",
      "Called API 30 times\n",
      "Called API 35 times\n",
      "Called API 40 times\n",
      "Called API 45 times\n",
      "Called API 50 times\n",
      "Called API 55 times\n",
      "Called API 60 times\n",
      "Called API 65 times\n",
      "Called API 70 times\n",
      "Called API 75 times\n",
      "Called API 80 times\n",
      "Called API 85 times\n",
      "Called API 90 times\n",
      "Called API 95 times\n",
      "Called API 100 times\n",
      "Called API 105 times\n",
      "Called API 110 times\n",
      "Called API 115 times\n",
      "Called API 120 times\n",
      "Called API 125 times\n",
      "Called API 130 times\n",
      "Called API 135 times\n",
      "Called API 140 times\n",
      "Called API 145 times\n",
      "Called API 150 times\n",
      "Called API 155 times\n",
      "Called API 160 times\n",
      "Called API 165 times\n",
      "Called API 170 times\n",
      "Called API 175 times\n",
      "Called API 180 times\n",
      "Called API 185 times\n",
      "Called API 190 times\n",
      "Called API 195 times\n",
      "Called API 200 times\n",
      "Called API 205 times\n",
      "Called API 210 times\n",
      "Called API 215 times\n",
      "Called API 220 times\n",
      "Called API 225 times\n",
      "Called API 230 times\n",
      "Called API 235 times\n",
      "Called API 240 times\n",
      "Called API 245 times\n",
      "Called API 250 times\n",
      "Called API 255 times\n",
      "Called API 260 times\n",
      "Called API 265 times\n",
      "Called API 270 times\n",
      "Called API 275 times\n",
      "Called API 280 times\n",
      "Called API 285 times\n",
      "Called API 290 times\n",
      "Called API 295 times\n",
      "Called API 300 times\n",
      "Called API 305 times\n",
      "Called API 310 times\n",
      "Called API 315 times\n",
      "Called API 320 times\n",
      "Called API 325 times\n",
      "Called API 330 times\n",
      "Called API 335 times\n",
      "Called API 340 times\n",
      "Called API 345 times\n",
      "Called API 350 times\n",
      "Called API 355 times\n",
      "Called API 360 times\n",
      "Called API 365 times\n",
      "Called API 370 times\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "list_of_years = [2019] #list of years to process\n",
    "\n",
    "for year in list_of_years:\n",
    "\n",
    "    #Import the JSON file, which is a list of objects\n",
    "    input_directory = f\"../dataset/epl_sentiment_analysis/bbc_articles_collated/bbc_collated_articles_{year}.json\" #change the year when needed\n",
    "    output_directory = f\"../dataset/epl_sentiment_analysis/sentiment_analysis_results_deepseek/deepseek_sentiment_{year}_output.json\" #change the year when needed\n",
    "\n",
    "    with open(input_directory, 'r') as file:\n",
    "        matches = json.load(file)\n",
    "\n",
    "    #check if the output file exists, if not define it as an empty list\n",
    "    if not os.path.exists(output_directory):\n",
    "        existing_output = []\n",
    "    else:\n",
    "        # Load the existing output file\n",
    "        with open(output_directory, 'r') as file:\n",
    "            existing_output = json.load(file)\n",
    "\n",
    "    def query_LLM_API(home_team, away_team, match_date, home_team_last_match_date, away_team_last_match_date, home_team_commentary, away_team_commentary):\n",
    "        try:\n",
    "            client = OpenAI(\n",
    "                api_key=os.getenv(\"DEEPSEEK_API_KEY\"), \n",
    "                base_url=\"https://api.deepseek.com/v1\",\n",
    "            )\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"deepseek-reasoner\", \n",
    "                messages=[\n",
    "                    {'role': 'system', \n",
    "                    'content': \"\"\"\n",
    "                                You are an advanced sentiment analysis assistant. \n",
    "                                Your task is to analyze match commentaries in the English Premier League. \n",
    "                                The sentiment rating on a certain team should be based on a 5-point scale: Strongly Positive (5), Positive (4), Neutral(3), Negative (2), or Strongly Negative (1)\n",
    "                                \"\"\"\n",
    "                        },\n",
    "                    {'role': 'user', \n",
    "                    'content': f\"\"\"\n",
    "                                I would like you to predict the sentiment for each team for the upcoming match based on what happened in the previous match. \n",
    "                                For the upcoming match on {match_date}, {home_team} is the home team and {away_team} is the away team. I have found the BBC commentaries of both teams’ previous matches. \n",
    "                                Rate the sentiment of each team on an output on a scale of 1-5. Reply in a JSON format with the following keys: home_team_sentiment, away_team_sentiment. Do not reply with anything else.\n",
    "\n",
    "                                Below are the articles:\n",
    "                                The article for {home_team}’s previous match on {home_team_last_match_date}: \n",
    "                                {home_team_commentary}\n",
    "                                \n",
    "                                The article for {away_team}’s previous match on {away_team_last_match_date}: \n",
    "                                {away_team_commentary}.\n",
    "                                \"\"\"\n",
    "                        }],\n",
    "                )\n",
    "            # Extract the response content from the completion object\n",
    "            response_content = completion.choices[0].message.content\n",
    "\n",
    "            # remove everything before the open curly brace and after the closing curly brace\n",
    "            response_content = response_content[response_content.find('{'):response_content.rfind('}') + 1]\n",
    "\n",
    "            #convert the string to a dictionary\n",
    "            response_dict = json.loads(response_content)\n",
    "\n",
    "            return response_dict\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "    #for each object in the list, get the home team, away team, match date, home team last match date, away team last match date, home team commentary, away team commentary\n",
    "\n",
    "    count = 0 #count will only increase if the API is called\n",
    "\n",
    "    final_output = [] #list to store the final output\n",
    "\n",
    "    for match in matches:\n",
    "\n",
    "        id =  match['id']\n",
    "        home_team = match['home_team']\n",
    "        away_team = match['away_team']\n",
    "        date = match['date']\n",
    "        home_team_last_match_date = match['home_team_last_match_date']\n",
    "        away_team_last_match_date = match['away_team_last_match_date']\n",
    "        home_team_commentary = match['bbc_article_home_team_last_match']\n",
    "        away_team_commentary = match['bbc_article_away_team_last_match']\n",
    "\n",
    "        #skip matches without home team commentary or away team commentary\n",
    "        if not home_team_commentary or not away_team_commentary:\n",
    "            continue\n",
    "\n",
    "        #check if the id is already in the output file, and that there is no existing sentiment for both the home team and away team\n",
    "        if any(existing_match['id'] == id and existing_match['home_team_sentiment'] is not None and existing_match['away_team_sentiment'] is not None for existing_match in existing_output):\n",
    "            #append the existing match to the final output and skip to the next match\n",
    "            final_output.append(next(existing_match for existing_match in existing_output if existing_match['id'] == id))\n",
    "            continue\n",
    "        \n",
    "        count += 1\n",
    "        if count % 5 == 0: #print every 10 matches\n",
    "            print(f\"Called API {count} times\")\n",
    "\n",
    "\n",
    "        # Call the function to query the LLM API\n",
    "        response = query_LLM_API(home_team, away_team, date, home_team_last_match_date, away_team_last_match_date, home_team_commentary, away_team_commentary)\n",
    "        if response is None:\n",
    "            print(f\"Iteration {count}: Error in API response.\")\n",
    "            final_output.append({\n",
    "                'id': id,\n",
    "                'home_team': home_team,\n",
    "                'away_team': away_team,\n",
    "                'date': date,\n",
    "                'home_team_sentiment': None,\n",
    "                'away_team_sentiment': None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "        final_output.append({\n",
    "            'id': id,\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'date': date,\n",
    "            'home_team_sentiment': response['home_team_sentiment'],\n",
    "            'away_team_sentiment': response['away_team_sentiment']\n",
    "        })\n",
    "    \n",
    "\n",
    "    #output the final output to a JSON file\n",
    "    with open(output_directory, 'w') as file:\n",
    "        json.dump(final_output, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e43a70",
   "metadata": {},
   "source": [
    "OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26467814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called API 10 times\n",
      "Called API 20 times\n",
      "Called API 30 times\n",
      "Called API 40 times\n",
      "Called API 50 times\n",
      "Called API 60 times\n",
      "Called API 70 times\n",
      "Called API 80 times\n",
      "Called API 90 times\n",
      "Called API 100 times\n",
      "Called API 110 times\n",
      "Called API 120 times\n",
      "Called API 130 times\n",
      "Called API 140 times\n",
      "Called API 150 times\n",
      "Called API 160 times\n",
      "Called API 170 times\n",
      "Called API 180 times\n",
      "Called API 190 times\n",
      "Called API 200 times\n",
      "Called API 210 times\n",
      "Called API 220 times\n",
      "Called API 230 times\n",
      "Called API 240 times\n",
      "Called API 250 times\n",
      "Called API 260 times\n",
      "Called API 270 times\n",
      "Called API 280 times\n",
      "Called API 290 times\n",
      "Called API 300 times\n",
      "Called API 310 times\n",
      "Called API 320 times\n",
      "Called API 330 times\n",
      "Called API 340 times\n",
      "Called API 350 times\n",
      "Called API 360 times\n",
      "Called API 370 times\n",
      "Called API 10 times\n",
      "Called API 20 times\n",
      "Called API 30 times\n",
      "Called API 40 times\n",
      "Called API 50 times\n",
      "Called API 60 times\n",
      "Called API 70 times\n",
      "Called API 80 times\n",
      "Called API 90 times\n",
      "Called API 100 times\n",
      "Called API 110 times\n",
      "Called API 120 times\n",
      "Called API 130 times\n",
      "Called API 140 times\n",
      "Called API 150 times\n",
      "Called API 160 times\n",
      "Called API 170 times\n",
      "Called API 180 times\n",
      "Called API 190 times\n",
      "Called API 200 times\n",
      "Called API 210 times\n",
      "Called API 220 times\n",
      "Called API 230 times\n",
      "Called API 240 times\n",
      "Called API 250 times\n",
      "Called API 260 times\n",
      "Called API 270 times\n",
      "Called API 280 times\n",
      "Called API 290 times\n",
      "Called API 300 times\n",
      "Called API 310 times\n",
      "Called API 320 times\n",
      "Called API 330 times\n",
      "Called API 340 times\n",
      "Called API 350 times\n",
      "Called API 360 times\n",
      "Called API 370 times\n",
      "Called API 10 times\n",
      "Called API 20 times\n",
      "Called API 30 times\n",
      "Called API 40 times\n",
      "Called API 50 times\n",
      "Called API 60 times\n",
      "Called API 70 times\n",
      "Called API 80 times\n",
      "Called API 90 times\n",
      "Called API 100 times\n",
      "Called API 110 times\n",
      "Called API 120 times\n",
      "Called API 130 times\n",
      "Called API 140 times\n",
      "Called API 150 times\n",
      "Called API 160 times\n",
      "Called API 170 times\n",
      "Called API 180 times\n",
      "Called API 190 times\n",
      "Called API 200 times\n",
      "Called API 210 times\n",
      "Called API 220 times\n",
      "Called API 230 times\n",
      "Called API 240 times\n",
      "Called API 250 times\n",
      "Called API 260 times\n",
      "Called API 270 times\n",
      "Called API 280 times\n",
      "Called API 290 times\n",
      "Called API 300 times\n",
      "Called API 310 times\n",
      "Called API 320 times\n",
      "Called API 330 times\n",
      "Called API 340 times\n",
      "Called API 350 times\n",
      "Called API 360 times\n",
      "Called API 370 times\n",
      "Called API 10 times\n",
      "Called API 20 times\n",
      "Called API 30 times\n",
      "Called API 40 times\n",
      "Called API 50 times\n",
      "Called API 60 times\n",
      "Called API 70 times\n",
      "Called API 80 times\n",
      "Called API 90 times\n",
      "Called API 100 times\n",
      "Called API 110 times\n",
      "Called API 120 times\n",
      "Called API 130 times\n",
      "Called API 140 times\n",
      "Called API 150 times\n",
      "Called API 160 times\n",
      "Called API 170 times\n",
      "Called API 180 times\n",
      "Called API 190 times\n",
      "Called API 200 times\n",
      "Called API 210 times\n",
      "Called API 220 times\n",
      "Called API 230 times\n",
      "Called API 240 times\n",
      "Called API 250 times\n",
      "Called API 260 times\n",
      "Called API 270 times\n",
      "Called API 280 times\n",
      "Called API 290 times\n",
      "Called API 300 times\n",
      "Called API 310 times\n",
      "Called API 320 times\n",
      "Called API 330 times\n",
      "Called API 340 times\n",
      "Called API 350 times\n",
      "Called API 360 times\n",
      "Called API 370 times\n",
      "Called API 10 times\n",
      "Called API 20 times\n",
      "Called API 30 times\n",
      "Called API 40 times\n",
      "Called API 50 times\n",
      "Called API 60 times\n",
      "Called API 70 times\n",
      "Called API 80 times\n",
      "Called API 90 times\n",
      "Called API 100 times\n",
      "Called API 110 times\n",
      "Called API 120 times\n",
      "Called API 130 times\n",
      "Called API 140 times\n",
      "Called API 150 times\n",
      "Called API 160 times\n",
      "Called API 170 times\n",
      "Called API 180 times\n",
      "Called API 190 times\n",
      "Called API 200 times\n",
      "Called API 210 times\n",
      "Called API 220 times\n",
      "Called API 230 times\n",
      "Called API 240 times\n",
      "Called API 250 times\n",
      "Called API 260 times\n",
      "Called API 270 times\n",
      "Called API 280 times\n",
      "Called API 290 times\n",
      "Called API 300 times\n",
      "Called API 310 times\n",
      "Called API 320 times\n",
      "Called API 330 times\n",
      "Called API 340 times\n",
      "Called API 350 times\n",
      "Called API 360 times\n",
      "Called API 10 times\n",
      "Called API 20 times\n",
      "Called API 30 times\n",
      "Called API 40 times\n",
      "Called API 50 times\n",
      "Called API 60 times\n",
      "Called API 70 times\n",
      "Called API 80 times\n",
      "Called API 90 times\n",
      "Called API 100 times\n",
      "Called API 110 times\n",
      "Called API 120 times\n",
      "Called API 130 times\n",
      "Called API 140 times\n",
      "Called API 150 times\n",
      "Called API 160 times\n",
      "Called API 170 times\n",
      "Called API 180 times\n",
      "Called API 190 times\n",
      "Called API 200 times\n",
      "Called API 210 times\n",
      "Called API 220 times\n",
      "Called API 230 times\n",
      "Called API 240 times\n",
      "Called API 250 times\n",
      "Called API 260 times\n",
      "Called API 270 times\n",
      "Called API 280 times\n",
      "Called API 290 times\n",
      "Called API 300 times\n",
      "Called API 310 times\n",
      "Called API 320 times\n",
      "Called API 330 times\n",
      "Called API 340 times\n",
      "Called API 350 times\n",
      "Called API 360 times\n",
      "Called API 10 times\n",
      "Called API 20 times\n",
      "Called API 30 times\n",
      "Called API 40 times\n",
      "Called API 50 times\n",
      "Called API 60 times\n",
      "Called API 70 times\n",
      "Called API 80 times\n",
      "Called API 90 times\n",
      "Called API 100 times\n",
      "Called API 110 times\n",
      "Called API 120 times\n",
      "Called API 130 times\n",
      "Called API 140 times\n",
      "Called API 150 times\n",
      "Called API 160 times\n",
      "Called API 170 times\n",
      "Called API 180 times\n",
      "Called API 190 times\n",
      "Called API 200 times\n",
      "Called API 210 times\n",
      "Called API 220 times\n",
      "Called API 230 times\n",
      "Called API 240 times\n",
      "Called API 250 times\n",
      "Called API 260 times\n",
      "Called API 270 times\n",
      "Called API 280 times\n",
      "Called API 290 times\n",
      "Called API 300 times\n",
      "Called API 310 times\n",
      "Called API 320 times\n",
      "Called API 330 times\n",
      "Called API 340 times\n",
      "Called API 350 times\n",
      "Called API 360 times\n",
      "Called API 370 times\n",
      "Called API 10 times\n",
      "Called API 20 times\n",
      "Called API 30 times\n",
      "Called API 40 times\n",
      "Called API 50 times\n",
      "Called API 60 times\n",
      "Called API 70 times\n",
      "Called API 80 times\n",
      "Called API 90 times\n",
      "Called API 100 times\n",
      "Called API 110 times\n",
      "Called API 120 times\n",
      "Called API 130 times\n",
      "Called API 140 times\n",
      "Called API 150 times\n",
      "Called API 160 times\n",
      "Called API 170 times\n",
      "Called API 180 times\n",
      "Called API 190 times\n",
      "Called API 200 times\n",
      "Called API 210 times\n",
      "Called API 220 times\n",
      "Called API 230 times\n",
      "Called API 240 times\n",
      "Called API 250 times\n",
      "Called API 260 times\n",
      "Called API 270 times\n",
      "Called API 280 times\n",
      "Called API 290 times\n",
      "Called API 300 times\n",
      "Called API 310 times\n",
      "Called API 320 times\n",
      "Called API 330 times\n",
      "Called API 340 times\n",
      "Called API 350 times\n",
      "Called API 360 times\n",
      "Called API 370 times\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "list_of_years = [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023] #list of years to process\n",
    "\n",
    "for year in list_of_years:\n",
    "\n",
    "    #Import the JSON file, which is a list of objects\n",
    "    input_directory = f\"../dataset/epl_sentiment_analysis/bbc_articles_collated/bbc_collated_articles_{year}.json\" #change the year when needed\n",
    "    output_directory = f\"../dataset/epl_sentiment_analysis/sentiment_analysis_results_openai_gpt4.1/openai4.1_sentiment_{year}_output.json\" #change the year when needed\n",
    "\n",
    "    with open(input_directory, 'r') as file:\n",
    "        matches = json.load(file)\n",
    "\n",
    "    #check if the output file exists, if not define it as an empty list\n",
    "    if not os.path.exists(output_directory):\n",
    "        existing_output = []\n",
    "    else:\n",
    "        # Load the existing output file\n",
    "        with open(output_directory, 'r') as file:\n",
    "            existing_output = json.load(file)\n",
    "\n",
    "    def query_LLM_API(home_team, away_team, match_date, home_team_last_match_date, away_team_last_match_date, home_team_commentary, away_team_commentary):\n",
    "        try:\n",
    "            client = OpenAI(\n",
    "                api_key= \"\"\n",
    "            )\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4.1\", \n",
    "                messages=[\n",
    "                    {'role': 'system', \n",
    "                    'content': \"\"\"\n",
    "                                You are an advanced sentiment analysis assistant. \n",
    "                                Your task is to analyze match commentaries in the English Premier League. \n",
    "                                The sentiment rating on a certain team should be based on a 5-point scale: Strongly Positive (5), Positive (4), Neutral(3), Negative (2), or Strongly Negative (1)\n",
    "                                \"\"\"\n",
    "                        },\n",
    "                    {'role': 'user', \n",
    "                    'content': f\"\"\"\n",
    "                                I would like you to predict the sentiment for each team for the upcoming match based on what happened in the previous match. \n",
    "                                For the upcoming match on {match_date}, {home_team} is the home team and {away_team} is the away team. I have found the BBC commentaries of both teams’ previous matches. \n",
    "                                Rate the sentiment of each team on an output on a scale of 1-5. Reply in a JSON format with the following keys: home_team_sentiment, away_team_sentiment. Do not reply with anything else.\n",
    "\n",
    "                                Below are the articles:\n",
    "                                The article for {home_team}’s previous match on {home_team_last_match_date}: \n",
    "                                {home_team_commentary}\n",
    "                                \n",
    "                                The article for {away_team}’s previous match on {away_team_last_match_date}: \n",
    "                                {away_team_commentary}.\n",
    "                                \"\"\"\n",
    "                        }],\n",
    "                )\n",
    "            # Extract the response content from the completion object\n",
    "            response_content = completion.choices[0].message.content\n",
    "\n",
    "            # remove everything before the open curly brace and after the closing curly brace\n",
    "            response_content = response_content[response_content.find('{'):response_content.rfind('}') + 1]\n",
    "\n",
    "            #convert the string to a dictionary\n",
    "            response_dict = json.loads(response_content)\n",
    "\n",
    "            return response_dict\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "    #for each object in the list, get the home team, away team, match date, home team last match date, away team last match date, home team commentary, away team commentary\n",
    "\n",
    "    count = 0 #count will only increase if the API is called\n",
    "\n",
    "    final_output = [] #list to store the final output\n",
    "\n",
    "    for match in matches:\n",
    "\n",
    "        id =  match['id']\n",
    "        home_team = match['home_team']\n",
    "        away_team = match['away_team']\n",
    "        date = match['date']\n",
    "        home_team_last_match_date = match['home_team_last_match_date']\n",
    "        away_team_last_match_date = match['away_team_last_match_date']\n",
    "        home_team_commentary = match['bbc_article_home_team_last_match']\n",
    "        away_team_commentary = match['bbc_article_away_team_last_match']\n",
    "\n",
    "        #skip matches without home team commentary or away team commentary\n",
    "        if not home_team_commentary or not away_team_commentary:\n",
    "            continue\n",
    "\n",
    "        #check if the id is already in the output file, and that there is no existing sentiment for both the home team and away team\n",
    "        if any(existing_match['id'] == id and existing_match['home_team_sentiment'] is not None and existing_match['away_team_sentiment'] is not None for existing_match in existing_output):\n",
    "            #append the existing match to the final output and skip to the next match\n",
    "            final_output.append(next(existing_match for existing_match in existing_output if existing_match['id'] == id))\n",
    "            continue\n",
    "        \n",
    "        count += 1\n",
    "        if count % 10 == 0: #print every 10 matches\n",
    "            print(f\"Called API {count} times\")\n",
    "\n",
    "        \"\"\" if count>1: #remove this line to process all matches\n",
    "            break \"\"\"\n",
    "\n",
    "        # Call the function to query the LLM API\n",
    "        response = query_LLM_API(home_team, away_team, date, home_team_last_match_date, away_team_last_match_date, home_team_commentary, away_team_commentary)\n",
    "        if response is None:\n",
    "            print(f\"Iteration {count}: Error in API response.\")\n",
    "            final_output.append({\n",
    "                'id': id,\n",
    "                'home_team': home_team,\n",
    "                'away_team': away_team,\n",
    "                'date': date,\n",
    "                'home_team_sentiment': None,\n",
    "                'away_team_sentiment': None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "        final_output.append({\n",
    "            'id': id,\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'date': date,\n",
    "            'home_team_sentiment': response['home_team_sentiment'],\n",
    "            'away_team_sentiment': response['away_team_sentiment']\n",
    "        })\n",
    "    \n",
    "\n",
    "    #output the final output to a JSON file\n",
    "    with open(output_directory, 'w') as file:\n",
    "        json.dump(final_output, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8814d1fc",
   "metadata": {},
   "source": [
    "Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "list_of_years = [2017,2018,2019,2020,2021,2022,2023]  # list of years to process\n",
    "\n",
    "for year in list_of_years:\n",
    "    # Import the JSON file\n",
    "    input_directory = f\"../dataset/epl_sentiment_analysis/bbc_articles_collated/bbc_collated_articles_{year}.json\"\n",
    "    output_directory = f\"../dataset/epl_sentiment_analysis/sentiment_analysis_results_openai/openai_sentiment_{year}_output.json\"\n",
    "\n",
    "    with open(input_directory, 'r') as file:\n",
    "        matches = json.load(file)\n",
    "\n",
    "    # Handle existing output\n",
    "    if not os.path.exists(output_directory):\n",
    "        existing_output = []\n",
    "    else:\n",
    "        with open(output_directory, 'r') as file:\n",
    "            existing_output = json.load(file)\n",
    "\n",
    "    def query_LLM_API(home_team, away_team, match_date, \n",
    "                     home_team_last_match_date, away_team_last_match_date,\n",
    "                     home_team_commentary, away_team_commentary):\n",
    "        try:\n",
    "            client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))  # Changed to OpenAI API key\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model= \"gpt-4o-mini\",  # Changed to GPT-4o mini model\n",
    "                response_format={\"type\": \"json_object\"},  # Ensure JSON response\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': 'system',\n",
    "                        'content': \"\"\"You are an advanced sentiment analysis assistant. \n",
    "                                     Your task is to analyze match commentaries in the English Premier League. \n",
    "                                     The sentiment rating should be based on a 5-point scale: \n",
    "                                     Strongly Positive (5), Positive (4), Neutral(3), Negative (2), or Strongly Negative (1)\"\"\"\n",
    "                    },\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': f\"\"\"Predict the sentiment for each team for the upcoming match based on previous match analysis.\n",
    "                                     For the match on {match_date}, {home_team} (home) vs {away_team} (away).\n",
    "                                     Provide JSON output with keys: home_team_sentiment, away_team_sentiment.\n",
    "\n",
    "                                     Previous matches:\n",
    "                                     - {home_team} ({home_team_last_match_date}): {home_team_commentary}\n",
    "                                     - {away_team} ({away_team_last_match_date}): {away_team_commentary}\"\"\"\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0.3  # Added for more consistent responses\n",
    "            )\n",
    "\n",
    "            # Directly parse JSON response\n",
    "            response_content = completion.choices[0].message.content\n",
    "            return json.loads(response_content)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Rest of the processing remains the same\n",
    "    final_output = []\n",
    "    count = 0\n",
    "\n",
    "    for match in matches:\n",
    "        id =  match['id']\n",
    "        home_team = match['home_team']\n",
    "        away_team = match['away_team']\n",
    "        date = match['date']\n",
    "        home_team_last_match_date = match['home_team_last_match_date']\n",
    "        away_team_last_match_date = match['away_team_last_match_date']\n",
    "        home_team_commentary = match['bbc_article_home_team_last_match']\n",
    "        away_team_commentary = match['bbc_article_away_team_last_match']\n",
    "\n",
    "        #skip matches without home team commentary or away team commentary\n",
    "        if not home_team_commentary or not away_team_commentary:\n",
    "            continue\n",
    "\n",
    "        #check if the id is already in the output file, and that there is no existing sentiment for both the home team and away team\n",
    "        if any(existing_match['id'] == id and existing_match['home_team_sentiment'] is not None and existing_match['away_team_sentiment'] is not None for existing_match in existing_output):\n",
    "            #append the existing match to the final output and skip to the next match\n",
    "            final_output.append(next(existing_match for existing_match in existing_output if existing_match['id'] == id))\n",
    "            continue\n",
    "        \n",
    "        count += 1\n",
    "        if count % 10 == 0: #print every 10 matches\n",
    "            print(f\"Called API {count} times\")\n",
    "\n",
    "        \"\"\" if count>1: #remove this line to process all matches\n",
    "            break \"\"\"\n",
    "\n",
    "        # Call the function to query the LLM API\n",
    "        response = query_LLM_API(home_team, away_team, date, home_team_last_match_date, away_team_last_match_date, home_team_commentary, away_team_commentary)\n",
    "        if response is None:\n",
    "            print(f\"Iteration {count}: Error in API response.\")\n",
    "            final_output.append({\n",
    "                'id': id,\n",
    "                'home_team': home_team,\n",
    "                'away_team': away_team,\n",
    "                'date': date,\n",
    "                'home_team_sentiment': None,\n",
    "                'away_team_sentiment': None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "        final_output.append({\n",
    "            'id': id,\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'date': date,\n",
    "            'home_team_sentiment': response['home_team_sentiment'],\n",
    "            'away_team_sentiment': response['away_team_sentiment']\n",
    "        })\n",
    "\n",
    "    # Save output\n",
    "    with open(output_directory, 'w') as file:\n",
    "        json.dump(final_output, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed21a4f",
   "metadata": {},
   "source": [
    "Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87aa224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "    \n",
    "list_of_years = [2019,2020,2021,2022,2023] #list of years to process\n",
    "\n",
    "for year in list_of_years:\n",
    "\n",
    "    #Import the JSON file, which is a list of objects\n",
    "    input_directory = f\"../dataset/epl_sentiment_analysis/bbc_articles_collated/bbc_collated_articles_{year}.json\" #change the year when needed\n",
    "    output_directory = f\"../dataset/epl_sentiment_analysis/sentiment_analysis_results_qwen/qwen_sentiment_{year}_output.json\" #change the year when needed\n",
    "\n",
    "    with open(input_directory, 'r') as file:\n",
    "        matches = json.load(file)\n",
    "\n",
    "    #check if the output file exists, if not define it as an empty list\n",
    "    if not os.path.exists(output_directory):\n",
    "        existing_output = []\n",
    "    else:\n",
    "        # Load the existing output file\n",
    "        with open(output_directory, 'r') as file:\n",
    "            existing_output = json.load(file)\n",
    "\n",
    "    def query_LLM_API(home_team, away_team, match_date, home_team_last_match_date, away_team_last_match_date, home_team_commentary, away_team_commentary):\n",
    "        try:\n",
    "            client = OpenAI(\n",
    "                api_key=os.getenv(\"QWEN_API_KEY\"), \n",
    "                base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    "            )\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"qwen-plus\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': 'system', \n",
    "                        'content': \"\"\"Your system content here\"\"\"\n",
    "                    },\n",
    "                    {\n",
    "                        'role': 'user', \n",
    "                        'content': f\"\"\"\n",
    "                        I would like you to predict the sentiment for each team for the upcoming match based on what happened in the previous match. \n",
    "                        For the upcoming match on {match_date}, {home_team} is the home team and {away_team} is the away team. I have found the BBC commentaries of both teams’ previous matches. \n",
    "                        Rate the sentiment of each team on a scale of 1-5. Reply in JSON format in the output below. Your response should be less than 100 characters.\n",
    "\n",
    "                        A sample output is:\n",
    "                        {{\n",
    "                            \"home_team_sentiment\": 4,\n",
    "                            \"away_team_sentiment\": 2\n",
    "                        }}\n",
    "\n",
    "                        Below are the articles:\n",
    "                        The article for {home_team}’s previous match on {home_team_last_match_date}: \n",
    "                        {home_team_commentary}\n",
    "                        \n",
    "                        The article for {away_team}’s previous match on {away_team_last_match_date}: \n",
    "                        {away_team_commentary}.\n",
    "                        \"\"\"\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # Extract and parse response\n",
    "            response_content = completion.choices[0].message.content\n",
    "\n",
    "            # remove everything before the open curly brace and after the closing curly brace\n",
    "            response_content = response_content[response_content.find('{'):response_content.rfind('}') + 1]\n",
    "\n",
    "            #convert the string to a dictionary\n",
    "            response_dict = json.loads(response_content)\n",
    "\n",
    "            return response_dict\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "    #for each object in the list, get the home team, away team, match date, home team last match date, away team last match date, home team commentary, away team commentary\n",
    "\n",
    "    count = 0 #count will only increase if the API is called\n",
    "\n",
    "    final_output = [] #list to store the final output\n",
    "\n",
    "    for match in matches:\n",
    "\n",
    "        id =  match['id']\n",
    "        home_team = match['home_team']\n",
    "        away_team = match['away_team']\n",
    "        date = match['date']\n",
    "        home_team_last_match_date = match['home_team_last_match_date']\n",
    "        away_team_last_match_date = match['away_team_last_match_date']\n",
    "        home_team_commentary = match['bbc_article_home_team_last_match']\n",
    "        away_team_commentary = match['bbc_article_away_team_last_match']\n",
    "\n",
    "        #skip matches without home team commentary or away team commentary\n",
    "        if not home_team_commentary or not away_team_commentary:\n",
    "            continue\n",
    "\n",
    "        #check if the id is already in the output file, and that there is no existing sentiment for both the home team and away team\n",
    "        if any(existing_match['id'] == id and existing_match['home_team_sentiment'] is not None and existing_match['away_team_sentiment'] is not None for existing_match in existing_output):\n",
    "            #append the existing match to the final output and skip to the next match\n",
    "            final_output.append(next(existing_match for existing_match in existing_output if existing_match['id'] == id))\n",
    "            continue\n",
    "        \n",
    "        count += 1\n",
    "        if count % 10 == 0: #print every 10 matches\n",
    "            print(f\"Called API {count} times\")\n",
    "\n",
    "        \"\"\" if count>1: #remove this line to process all matches\n",
    "            break \"\"\"\n",
    "\n",
    "        # Call the function to query the LLM API\n",
    "        response = query_LLM_API(home_team, away_team, date, home_team_last_match_date, away_team_last_match_date, home_team_commentary, away_team_commentary)\n",
    "        \n",
    "        if response is None:\n",
    "            print(f\"Iteration {count}: Error in API response.\")\n",
    "            final_output.append({\n",
    "                'id': id,\n",
    "                'home_team': home_team,\n",
    "                'away_team': away_team,\n",
    "                'date': date,\n",
    "                'home_team_sentiment': None,\n",
    "                'away_team_sentiment': None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "        final_output.append({\n",
    "            'id': id,\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'date': date,\n",
    "            'home_team_sentiment': response['home_team_sentiment'],\n",
    "            'away_team_sentiment': response['away_team_sentiment']\n",
    "        })\n",
    "    \n",
    "\n",
    "    #output the final output to a JSON file\n",
    "    with open(output_directory, 'w') as file:\n",
    "        json.dump(final_output, file, indent=4)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c99bb1",
   "metadata": {},
   "source": [
    "Combining All 3 LLM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93accff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "years_to_combine = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023] #list of years to process\n",
    "\n",
    "for year in years_to_combine:\n",
    "\n",
    "    #open up all 3 files first\n",
    "    deepseek_file = f\"../dataset/epl_sentiment_analysis/sentiment_analysis_results_deepseek/deepseek_sentiment_{year}_output.json\"\n",
    "    openai_file = f\"../dataset/epl_sentiment_analysis/sentiment_analysis_results_openai/openai_sentiment_{year}_output.json\"\n",
    "    qwen_file = f\"../dataset/epl_sentiment_analysis/sentiment_analysis_results_qwen/qwen_sentiment_{year}_output.json\"\n",
    "    openai41_file = f\"../dataset/epl_sentiment_analysis/sentiment_analysis_results_openai_gpt4.1/openai4.1_sentiment_{year}_output.json\"\n",
    "\n",
    "    with open(deepseek_file, 'r') as file:\n",
    "        deepseek_matches = json.load(file)\n",
    "\n",
    "    with open(openai_file, 'r') as file:\n",
    "        openai_matches = json.load(file)\n",
    "\n",
    "    with open(qwen_file, 'r') as file:\n",
    "        qwen_matches = json.load(file)\n",
    "\n",
    "    with open(openai41_file, 'r') as file:\n",
    "        openai41_matches = json.load(file)\n",
    "\n",
    "    combined_output = [] #list to store the final output\n",
    "\n",
    "    for match in deepseek_matches:\n",
    "        id = match['id']\n",
    "        home_team = match['home_team']\n",
    "        away_team = match['away_team']\n",
    "        date = match['date']\n",
    "        \n",
    "        # Find corresponding matches in OpenAI and Qwen files\n",
    "        openai_match = next((m for m in openai_matches if m['id'] == id), None)\n",
    "        qwen_match = next((m for m in qwen_matches if m['id'] == id), None)\n",
    "        openai41_match = next((m for m in openai41_matches if m['id'] == id), None)\n",
    "\n",
    "\n",
    "        # Combine the data\n",
    "        combined_output.append({\n",
    "            'id': id,\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'date': date,\n",
    "            'deepseek_home_team_sentiment': match['home_team_sentiment'],\n",
    "            'deepseek_away_team_sentiment': match['away_team_sentiment'],\n",
    "            'deepseek_home-away_sentiment': match['home_team_sentiment'] - match['away_team_sentiment'],\n",
    "            'openai_home_team_sentiment': openai_match['home_team_sentiment'] if openai_match else None,\n",
    "            'openai_away_team_sentiment': openai_match['away_team_sentiment'] if openai_match else None,\n",
    "            'openai_home-away_sentiment': openai_match['home_team_sentiment'] - openai_match['away_team_sentiment'],\n",
    "            'qwen_home_team_sentiment': qwen_match['home_team_sentiment'] if qwen_match else None,\n",
    "            'qwen_away_team_sentiment': qwen_match['away_team_sentiment'] if qwen_match else None,\n",
    "            'qwen_home-away_sentiment':qwen_match['home_team_sentiment'] - qwen_match['away_team_sentiment'],\n",
    "            'openai4.1_home_team_sentiment': openai41_match['home_team_sentiment'] if openai41_match else None,\n",
    "            'openai4.1_away_team_sentiment': openai41_match['away_team_sentiment'] if openai41_match else None,\n",
    "            'openai4.1_home-away_sentiment': openai41_match['home_team_sentiment'] - openai41_match['away_team_sentiment']\n",
    "        })\n",
    "\n",
    "    #output the final output to a JSON file\n",
    "    combined_output_file = f\"../dataset/epl_sentiment_analysis/sentiment_analysis_results_combined/combined_sentiment_{year}_output.json\"\n",
    "    with open(combined_output_file, 'w') as file:\n",
    "        json.dump(combined_output, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5049881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
